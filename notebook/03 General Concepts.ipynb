{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Unit 03 - General Concepts**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.1 Typical Flow**\n",
    "\n",
    "Below is the typical flow when you are trying to solve a problem. The sequence is not hard-set and you almost always iterate several times back and forth.\n",
    "\n",
    "1. **Research/Requirement specification:**\n",
    "    - Know your domain. Market research to explore possible benefits of predictive analytics to end users and revenue it could generate.\n",
    "    - A specific problem that needs solving by a stakeholder. \n",
    "    - You are just given a dump of data that your stakeholder thinks can provide value. Look at it from the big picture. Understand what the stakeholder does and how the data is generated. Identify gaps that can be filled or efficiency that can be brought about.\n",
    "\n",
    "\n",
    "2. **Formalize your Objective:** At this stage you must be clear what is it that you want to solve. It helps if you make a custom checklist. Ask yourself every possible question you can think of.\n",
    "    - What is the goal of the project? What are we trying to solve?\n",
    "    - Who will benefit from this?\n",
    "    - What is the current solution to the problem you are solving? How good/bad is it?\n",
    "    - Do you have data? How can you collect it? Where is it stored?\n",
    "    - Does your data have labels? (Supervised/Un-supervised/Semi-supervised) If not, can you or somebody help you with labelling?\n",
    "    - Is it a classification task? Regression task? Something else?\n",
    "    - Does it require batch learning or online learning?\n",
    "    - What is the measure of performance? What would be deemed acceptable by the stakeholder?\n",
    "    - What are the assumptions made?\n",
    "    - Many more based on your problem ...\n",
    "    \n",
    "    \n",
    "3. **Get your data**: \n",
    "    - Your stakeholder may provide you the data - files or a database.\n",
    "    - You may have to gather it yourself. Explore different sources. Conduct surveys.\n",
    "    - Or both if either are not sufficient !\n",
    "    - Your models will be built on what we call `training set`. This is typically 70-80 % for most datasets. The remaining data is called the `test set`. We do not touch this till the end because we want the model to generalize better to new unseen data.\n",
    "    \n",
    "    \n",
    "4. **Exploratory Analysis**: \n",
    "    - Use only the `training set`. Do not look at the `test set`. This to avoid what we call `snooping bias`. \n",
    "    - Understand your data. \n",
    "    - Know the statistics and data distributions. \n",
    "    - Visualize. Make inferences on what the data is telling you. \n",
    "    - Make sanity checks. Check quality of data.\n",
    "    - Identify missing data and think of strategies best to deal with it.\n",
    "    - Revisit and fine tune your problem formulation based on what you infer.\n",
    "    - Preprocess the data in a way it can be further used for modelling\n",
    "    \n",
    "    \n",
    "5. **Training a model**: \n",
    "    - Depending on your understanding the data, pick potentially suitable models and train it. \n",
    "    - Fine tune models to get best results. \n",
    "    - Analyze and interpret the results of your model. Evaluate the performance on the `test set`. \n",
    "    \n",
    "    \n",
    "6. **Deploy your solution**: This is case dependent. \n",
    "    - Your end goal could be a report to show business executives what decisions they should take. \n",
    "    - It could be a application which will benefit the end user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.2 Exploratory Data Analysis**\n",
    "\n",
    "It is important for us to understand the data we work with. We should know it better than the model we try build with it. This is essential so that you understand why the model predicts something a certain way.\n",
    "\n",
    "Data can be -\n",
    "- **Structured**: It is in tabular form with `m` rows and `n` columns. The rows are called as `examples`. The columns are called as `features`.\n",
    "- **Unstructured**: There is no defined structure. You cannot directly apply an algorithm without some preprocessing. Eg: Text documents, images.\n",
    "\n",
    "#### **Objectives of an EDA**\n",
    "- Identify the types of data. \n",
    "- Obtain descriptive statistics. \n",
    "- Identify quirks or inconsistencies in the data.\n",
    "- Know the distributions of the data.\n",
    "- Predictive power of each of the features. To see if the features are correlated with the target variable.\n",
    "- Most importantly, to understand what you are trying to solve and whether you can explain it with your data.\n",
    "\n",
    "#### Types of data\n",
    "- Categorical data:\n",
    "    - Nominal\n",
    "    - Ordinal\n",
    "- Continuous data:\n",
    "    - Interval:\n",
    "    - Ratio:\n",
    "\n",
    "### 3.1 Descriptive / Univariate Analysis\n",
    "\n",
    "Univariate Analysis\n",
    "- Central Tendency\n",
    "    - mean\n",
    "    - median\n",
    "    - mode\n",
    "- Variability\n",
    "    - Range\n",
    "    - Variance\n",
    "    - Interquartile range\n",
    "\n",
    "- Categorical Variables\n",
    "    - Bar chart\n",
    "- Continuous Variables\n",
    "    - Bar chart (not good)/density chart\n",
    "    - Box plot\n",
    "    \n",
    "### 3.2 Correlation Analysis\n",
    "- Categorical and Categorical\n",
    "- Continuous and Continuous\n",
    "- Categorical and continuous\n",
    "\n",
    "Outcome - \n",
    "- Determine which features have predictive power\n",
    "- Determine redundant features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Model Training\n",
    "\n",
    "### Model Evaluation\n",
    "\n",
    "### Bias and Variance\n",
    "\n",
    "\n",
    "### Overfitting and underfitting\n",
    "\n",
    "### Regularization\n",
    "\n",
    "\n",
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
